/>Frank: arXiv 2010[Google]: Sharpness-Aware Minimization for Efficiently Improving Generalization
你看看知乎那个人评论的 效果最好的是ICLR 20年的那几篇
github有pytorch 实现代码那篇论文
一般奇数次累加 偶数次清零  他这个地方写的比较复杂
更多训练代码细节可以在作者这个地方询问 https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-train-amp-aug

可以看下这篇论文 A predictive machine learning application in agriculture: Cassava disease detection and classification with imbalanced dataset using convolutional neural networks 去年木薯叶检测和分类是在一个CVPR workshop举办的. 第一个任务是目标检测检测出木薯叶的位置，第二个任务是对木薯叶疾病进行分类。

/>garry：他们说的2019dataset是啥 2019年有过这比赛 https://www.kaggle.com/c/cassava-disease/overview
2070s 一个 epoch 10min

当年小麦检测是ECCV的workshop当时群里有同学最后验证自己比赛idea，投稿到了ECCV
后面最重要的还是noisy label的处理 然后就是把 去年这个比赛的数据集加上去
调参按照他SOTA那个准确度的超参设置就行

/>卷卷：老师之前讲的nni自动调参，新的yolov5直接把功能加进去了

他的SOTA是对标COCO的，我数据集用的其他的

/>马建华：colab需要把网盘里面的数据放到本地，要不然会不断的去网盘里面拖数据。会特别慢
对，所以最好在colab上面使用kaggle API直接把数据从kaggle放到colab的路径中
就不用从google drive把数据拖到本地

/>Awk：可以看看这个https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/203111 ， 有个变态用一个b4 + 2019 dataset 单个模型上到LB0.904

/>BlackCoffee：Tta 挑几个好点儿的模型融合，就能到 902

/>@助教-Frank 我打算用label smoothing 处理训练集的标签，那验证集标签需要处理？
不处理
请教个问题 模型融合的时候可以用B5 和B4这样混合着搭配吗？@助教-Frank 融合一般用不同模型.

老师的basebine跑出来的准确率是多少呢？第四个 epoch 就 89.6 了吧。。。好像后面随着 epoch 增加 准确率反而下降了

/>Roitman：@助教-Frank 助教老哥，请教个问题，目前baseline的Loss基本在0.3多。有没可能是陷入local minimum（学习率过小），或者在全局最小值附近反复震荡（学习率过大）？ 因为不知道实际情况是如何，怎么做一个学习率的调整策略比较好？还是这个baseline给的学习率和学习率调整策略基本是最优的了，在其他条件不该变的情况下，调整学习率以及学习率策略的提升空间不大

/>Frank：这个作者肯定是个其他optimizer scheduler

![image-20210122150408320](C:%5CUsers%5C86182%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210122150408320.png)

Torch1.6能跑老师的代码吗？卷卷：我之前好像试过1.6.1不可以，autocast不能用好像是

肾小球有讲怎么使用外部数据

请问有模型融合的教程 谷歌搜 Out-of-fold Predictions  哪个kaggle比赛都会用到的

随便搜最新SOTA的有代码的 ICLR 2020: DivideMix: Learning with Noisy Labels as Semi-supervised Learning 关键字：noisy label 如何解决noisy label是个难点，对自己提升也有帮助

snapmix是啥  新的数据增强：AAAI 2021: SnapMix: Semantically Proportional Mixing for Augmenting Fine-grained Data

/>TuTTuRu: snapmix默认 sam才要调 snapmix基本不用调,直接调用github自己改下 那可能你模型输出层那部分有问题 建议对比github上怎么改的模型 20个epoch

这个人的EDA做的非常好 肾小球那个比赛他也有做EDA https://www.kaggle.com/ihelon/cassava-leaf-disease-exploratory-data-analysis

Baseline默认是没有加mix系列增强的，老哥你是加了后实验掉点了吗？BlackCoffee:对，加了尝试了，没效果。

wlsh:
2002的一篇论文用到了这个比赛处理数据不均衡SMOTE: Synthetic Minority Over-sampling Technique: https://arxiv.org/abs/1106.1813

wlsh:
看一下这篇论文处理长尾数据问题 南京大学lamda实验室做的 AAAI 2021 Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks http://www.lamda.nju.edu.cn/zhangys/papers/AAAI_tricks.pdf

Crowdhuman人体检测比赛第一名经验总结 - Caleb Ge的文章 - 知乎
https://zhuanlan.zhihu.com/p/68677880